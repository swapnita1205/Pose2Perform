{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "D5CmW5MlsjcQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U yt_dlp youtube-search-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy"
      ],
      "metadata": {
        "id": "UhyOjiXZBKvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23180905-7256-4f73-93dc-4a484f193f3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.11)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install \"httpx<0.27\" --force-reinstall"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Y4x747NJs27a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python3 -m pip install opencv-python==4.9.0.80 mediapipe==0.10.5 torch==2.2.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dbtiKV52wn41"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtubesearchpython import VideosSearch\n",
        "import yt_dlp\n",
        "import os\n",
        "\n",
        "def parse_duration(duration_str):\n",
        "    parts = duration_str.split(':')\n",
        "    if len(parts) == 2:  # mm:ss\n",
        "        minutes, seconds = map(int, parts)\n",
        "        return minutes * 60 + seconds\n",
        "    elif len(parts) == 3:  # hh:mm:ss\n",
        "        hours, minutes, seconds = map(int, parts)\n",
        "        return hours * 3600 + minutes * 60 + seconds\n",
        "    return 0  # if unknown or invalid\n",
        "\n",
        "def download_videos(query, label, num_videos=5, save_dir='videos'):\n",
        "    path = os.path.join(save_dir, label)\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    collected = 0\n",
        "    search = VideosSearch(query, limit=30)  # Fetch more to filter\n",
        "\n",
        "    for result in search.result()['result']:\n",
        "        if 'duration' not in result:\n",
        "            continue  # Skip livestreams or missing info\n",
        "\n",
        "        duration_sec = parse_duration(result['duration'])\n",
        "        if duration_sec >= 300:\n",
        "            continue  # Skip videos 5 min or longer\n",
        "\n",
        "        url = result['link']\n",
        "        output_filename = os.path.join(path, f\"{label}_{collected + 1}.mp4\")\n",
        "\n",
        "        ydl_opts = {\n",
        "            'format': 'best[ext=mp4]/best',\n",
        "            'outtmpl': output_filename,\n",
        "            'quiet': True,\n",
        "            'noplaylist': True,\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"Downloading [{label}] video {collected + 1}: {result['title']}\")\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([url])\n",
        "            collected += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {url}: {e}\")\n",
        "\n",
        "        if collected >= num_videos:\n",
        "            break\n",
        "\n",
        "# Download 5 short ballet and 5 short hip-hop videos\n",
        "download_videos(\"ballet dance performance\", \"ballet\", num_videos=10)\n",
        "download_videos(\"hip hop dance performance\", \"hiphop\", num_videos=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waUTScNZskzz",
        "outputId": "41aab643-14c9-4e2e-cc61-4579b72bc96d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [ballet] video 1: Dance of the Sugar Plum Fairy from The Nutcracker (The Royal Ballet)\n",
            "Downloading [ballet] video 2: Swan Lake ‚Äì Dance of the cygnets (The Royal Ballet)\n",
            "Downloading [ballet] video 3: Don Quixote ‚Äì Act III Kitri Variation (Akane Takada, The Royal Ballet)\n",
            "Downloading [ballet] video 4: Winter Waltz - CASA DE BALET\n",
            "Downloading [ballet] video 5: LED Ballerinas - Ballerina Dance / Modern Ballet Show - Contraband Entertainment\n",
            "Downloading [ballet] video 6: Ella is FLYING üòçü©∞‚ú® #ballerina #ballet #shorts #ad\n",
            "Downloading [ballet] video 7: Can‚Äôt Help Falling in Love|Emotional Ballet Performance\n",
            "Downloading [ballet] video 8: Jeeho Lee WOWS the audience with the La Esmeralda Finale!\n",
            "Downloading [ballet] video 9: 12 years of ballet vs 2 üíÄüò± #ballet #challenge\n",
            "Downloading [ballet] video 10: Rewrite The Stars - Daniel Jang | Ballet, PERFORMING ARTS STUDIO PH\n",
            "Downloading [hiphop] video 1: 10 year old KILLS adult level dance üò± #notlikeus #dance\n",
            "Downloading [hiphop] video 2: Hip Hop Class was üî•üî•#shorts\n",
            "Downloading [hiphop] video 3: Havens team took 1st Overall for this HipHop Routine ü¶ñüôåüèº Congrats girls!! #dance #dancer #garzacrew\n",
            "Downloading [hiphop] video 4: 12 year old dancer shocks everyone üò±\n",
            "Downloading [hiphop] video 5: WHOLE CROWD TURNED UP WHEN THE DJ DROPPED ‚ÄúNOT LIKE US‚Äù üíØüå¥ #redbulldanceyourstyle #dancebattle\n",
            "Downloading [hiphop] video 6: No Lie - Sean Paul, Dua Lipa / Caruchan x Kchan Choreography dancepractice\n",
            "Downloading [hiphop] video 7: We heard you wanted the front view¬†üôÇ‚Äç‚ÜïÔ∏è\n",
            "Downloading [hiphop] video 8: Miyu with the heat! üî•üî•üî•\n",
            "Downloading [hiphop] video 9: Jazz Dancer vs Hip Hop Dancer!! Who won?\n",
            "Downloading [hiphop] video 10: Yeah ‚Ä¢ Usher | Dance Cover\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def split_video(video_path, clip_length=30, output_dir=\"clips\"):\n",
        "    try:\n",
        "        video = VideoFileClip(video_path)\n",
        "        duration = int(video.duration)\n",
        "        base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        clip_count = 0\n",
        "        for start in range(0, duration, clip_length):\n",
        "            end = min(start + clip_length, duration)\n",
        "            subclip = video.subclip(start, end)\n",
        "            output_path = os.path.join(output_dir, f\"{base_name}_part{clip_count + 1}.mp4\")\n",
        "            subclip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
        "            clip_count += 1\n",
        "\n",
        "        print(f\"‚úÖ Done: {video_path} ‚Üí {clip_count} clips.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to process {video_path}: {e}\")\n",
        "\n",
        "# Process all videos in both folders\n",
        "for label in ['ballet', 'hiphop']:\n",
        "    input_dir = f\"videos/{label}\"\n",
        "    output_dir = f\"clips/{label}\"\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".mp4\"):\n",
        "            full_path = os.path.join(input_dir, filename)\n",
        "            split_video(full_path, clip_length=30, output_dir=output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eLqkRLn2sGR",
        "outputId": "ab331d9b-7c71-42c2-cff4-f03f42541e90"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done: videos/ballet/ballet_9.mp4 ‚Üí 2 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_10.mp4 ‚Üí 3 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_6.mp4 ‚Üí 1 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_3.mp4 ‚Üí 3 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_7.mp4 ‚Üí 6 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_8.mp4 ‚Üí 1 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_5.mp4 ‚Üí 6 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_4.mp4 ‚Üí 7 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_2.mp4 ‚Üí 4 clips.\n",
            "‚úÖ Done: videos/ballet/ballet_1.mp4 ‚Üí 6 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_10.mp4 ‚Üí 1 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_8.mp4 ‚Üí 2 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_1.mp4 ‚Üí 1 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_4.mp4 ‚Üí 1 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_5.mp4 ‚Üí 2 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_7.mp4 ‚Üí 1 clips.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file videos/hiphop/hiphop_3.mp4, 691200 bytes wanted but 0 bytes read,at frame 659/661, at time 21.99/22.04 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done: videos/hiphop/hiphop_3.mp4 ‚Üí 1 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_9.mp4 ‚Üí 1 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_2.mp4 ‚Üí 2 clips.\n",
            "‚úÖ Done: videos/hiphop/hiphop_6.mp4 ‚Üí 1 clips.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "SmzkCR1Tybtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb680ce-1d51-43cb-b9fb-6b33238b55c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-203fbf1da191>\", line 4, in <cell line: 0>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1471, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Config\n",
        "# ----------------------\n",
        "TARGET_SIZE = (224, 224)\n",
        "SEQUENCE_LENGTH = 32\n",
        "STRIDE = 16\n",
        "USE_SKELETON = True\n",
        "NUM_CLASSES = 5"
      ],
      "metadata": {
        "id": "EJXUdBVRygA8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Pose Estimation Setup\n",
        "# ----------------------\n",
        "mp_pose = mp.solutions.pose\n",
        "pose_model = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
        "\n",
        "def extract_pose(frame):\n",
        "    results = pose_model.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    if not results.pose_landmarks:\n",
        "        return np.zeros((33, 3))  # x, y, z\n",
        "    return np.array([[l.x, l.y, l.z] for l in results.pose_landmarks.landmark])"
      ],
      "metadata": {
        "id": "3EmkRabcyiLW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path, use_pose=True, frame_skip=5):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames, keypoints = [], []\n",
        "    frame_idx = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % frame_skip == 0:\n",
        "            frame = cv2.resize(frame, TARGET_SIZE)\n",
        "\n",
        "            if use_pose:\n",
        "                keypoints.append(extract_pose(frame).flatten())\n",
        "\n",
        "            frame = frame.astype(np.float32) / 255.0\n",
        "            frames.append(frame)\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames), np.array(keypoints) if use_pose else None"
      ],
      "metadata": {
        "id": "XGxWvYIzyj7u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Create Fixed-Length Clips\n",
        "# ----------------------\n",
        "def create_clips(frames, keypoints=None, sequence_length=32, stride=16):\n",
        "    clips, pose_clips = [], []\n",
        "    for i in range(0, len(frames) - sequence_length + 1, stride):\n",
        "        if keypoints is not None:\n",
        "            pose_clip = keypoints[i:i + sequence_length]\n",
        "            if len(pose_clip) == sequence_length:\n",
        "                pose_clips.append(pose_clip)\n",
        "\n",
        "    return np.array(pose_clips)"
      ],
      "metadata": {
        "id": "v3uIu9WkymBN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# LSTM Model\n",
        "# ----------------------\n",
        "class PoseLSTM(nn.Module):\n",
        "    def __init__(self, input_size=99, hidden_size=128, num_layers=2, num_classes=NUM_CLASSES):\n",
        "        super(PoseLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        return self.fc(out)"
      ],
      "metadata": {
        "id": "Yp8i1yYPyn7f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Train Model\n",
        "# ----------------------\n",
        "def train_model(video_paths, labels):\n",
        "    all_clips = []\n",
        "    all_labels = []\n",
        "\n",
        "    for i, video in enumerate(video_paths):\n",
        "        _, keypoints = process_video(video, use_pose=True, frame_skip=5)\n",
        "        pose_clips = create_clips(_, keypoints, sequence_length=SEQUENCE_LENGTH, stride=STRIDE)\n",
        "        all_clips.extend(pose_clips)\n",
        "        all_labels.extend([labels[i]] * len(pose_clips))\n",
        "\n",
        "    X = torch.tensor(np.stack(all_clips)).float()\n",
        "    y = torch.tensor(all_labels).long()\n",
        "\n",
        "    dataset = TensorDataset(X, y)\n",
        "    loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "    model = PoseLSTM()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(5):\n",
        "        for xb, yb in loader:\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "sn1qFNhWypto"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------\n",
        "# Predict on New Video\n",
        "# ----------------------\n",
        "def predict(video_path, model):\n",
        "    _, keypoints = process_video(video_path, use_pose=True)\n",
        "    pose_clips = create_clips(_, keypoints, sequence_length=SEQUENCE_LENGTH, stride=STRIDE)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = torch.tensor(pose_clips).float()\n",
        "        outputs = model(inputs)\n",
        "        avg_probs = torch.softmax(outputs, dim=1).mean(dim=0)\n",
        "        pred_class = torch.argmax(avg_probs).item()\n",
        "\n",
        "    return pred_class"
      ],
      "metadata": {
        "id": "E2HOajqHyrcA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_labeled_video_paths(clip_dir='clips'):\n",
        "    train_videos, train_labels = [], []\n",
        "    test_videos, test_labels = [], []\n",
        "\n",
        "    for label_name, label_value in [('ballet', 0), ('hiphop', 1)]:\n",
        "        folder_path = os.path.join(clip_dir, label_name)\n",
        "        video_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.mp4')])\n",
        "\n",
        "        if len(video_files) < 2:\n",
        "            raise ValueError(f\"Not enough videos in {folder_path} to split into train/test.\")\n",
        "\n",
        "        random.shuffle(video_files)  # Shuffle to randomize test selection\n",
        "\n",
        "        test_file = video_files.pop()  # Leave one for testing\n",
        "        test_videos.append(os.path.join(folder_path, test_file))\n",
        "        test_labels.append(label_value)\n",
        "\n",
        "        for file in video_files:\n",
        "            train_videos.append(os.path.join(folder_path, file))\n",
        "            train_labels.append(label_value)\n",
        "\n",
        "    return train_videos, train_labels, test_videos, test_labels\n"
      ],
      "metadata": {
        "id": "i5WQbEB76X0r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_videos, train_labels, test_videos, test_labels = get_labeled_video_paths()\n",
        "model = train_model(train_videos, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALGJ9kIZyvXu",
        "outputId": "17128bd0-9783-415c-bc91-30d26205c6ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9548\n",
            "Epoch 2, Loss: 0.6637\n",
            "Epoch 3, Loss: 0.5656\n",
            "Epoch 4, Loss: 0.5386\n",
            "Epoch 5, Loss: 0.5886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüß™ Test Results:\")\n",
        "for i, video_path in enumerate(test_videos):\n",
        "    pred = predict(video_path, model)\n",
        "    print(f\"Video: {os.path.basename(video_path)} | Actual: {test_labels[i]} | Predicted: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hul6VNn0WQh",
        "outputId": "d90af8ea-9075-485a-c2d1-c7e82f7fd225"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Test Results:\n",
            "Video: ballet_1_part5.mp4 | Actual: 0 | Predicted: 0\n",
            "Video: hiphop_1_part1.mp4 | Actual: 1 | Predicted: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fXM5RcTc3zd4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}